{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4def92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980f8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_model = \"gpt-4o-mini\"\n",
    "openai_llm = ChatOpenAI(model=openai_model, temperature=0.1)\n",
    "\n",
    "groq_model = \"gemma2-9b-it\"\n",
    "groq_llm = ChatGroq(model=groq_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5808671",
   "metadata": {},
   "source": [
    "## Basic Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee30c26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi! üëã  What can I do for you today? üòÑ\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 11, 'total_tokens': 27, 'completion_time': 0.029090909, 'prompt_time': 0.001180179, 'queue_time': 0.25046044, 'total_time': 0.030271088}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--660d34c9-7162-481c-8a5c-c8bbb1626fdf-0', usage_metadata={'input_tokens': 11, 'output_tokens': 16, 'total_tokens': 27})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_llm.invoke(\"Hi GPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364aa12f",
   "metadata": {},
   "source": [
    "# Create chain using prompt and LLM.\n",
    "\n",
    "The chain will do the following:\n",
    "\n",
    "1. Format the prompt\n",
    "2. generate using LLM\n",
    "3. Output\n",
    "\n",
    "\n",
    "Chain is created using LCEL.\n",
    "\n",
    "In the following chain the output of LLM is an AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9b8e7",
   "metadata": {},
   "source": [
    "## Passing prompts directly via tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a10be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are the planets in Earth's solar system, in order from the sun:\\n\\n- Mercury\\n- Venus\\n- Earth\\n- Mars\\n- Jupiter\\n- Saturn\\n- Uranus\\n- Neptune \\n\\n\\nLet me know if you have any other questions!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 44, 'total_tokens': 100, 'completion_time': 0.101818182, 'prompt_time': 0.001647019, 'queue_time': 0.25350609, 'total_time': 0.103465201}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--70798e80-a776-4415-ac53-a7f79bc07ed0-0', usage_metadata={'input_tokens': 44, 'output_tokens': 56, 'total_tokens': 100})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant who is able to provide answers to questions\"\n",
    "user_prompt = \"Answer the following question: What are the names of planet in Earth's solar system.\"\n",
    "\n",
    "basic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{system_prompt}\"),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "\n",
    "# print(basic_prompt)\n",
    "\n",
    "chain = basic_prompt | groq_llm\n",
    "chain.invoke({\"system_prompt\": system_prompt, \"user_prompt\":user_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34660712",
   "metadata": {},
   "source": [
    "### Add OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffe362fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are the names of the planets in Earth's solar system, in order from the Sun:\\n\\n1. **Mercury**\\n2. **Venus**\\n3. **Earth**\\n4. **Mars**\\n5. **Jupiter**\\n6. **Saturn**\\n7. **Uranus**\\n8. **Neptune** \\n\\n\\nLet me know if you have any other questions! ü™êüöÄ\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant who is able to provide answers to questions\"\n",
    "user_prompt = \"Answer the following question: What are the names of planet in Earth's solar system.\"\n",
    "\n",
    "basic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{system_prompt}\"),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "\n",
    "# print(basic_prompt)\n",
    "\n",
    "chain = basic_prompt | groq_llm | StrOutputParser()\n",
    "chain.invoke({\"system_prompt\": system_prompt, \"user_prompt\":user_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5b629",
   "metadata": {},
   "source": [
    "## Use a JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f129c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['user_prompt'] input_types={} partial_variables={'format_instruction': 'Return a JSON object.'} template='{user_prompt}. Respond with format: {format_instruction}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'planets': ['Mercury',\n",
       "  'Venus',\n",
       "  'Earth',\n",
       "  'Mars',\n",
       "  'Jupiter',\n",
       "  'Saturn',\n",
       "  'Uranus',\n",
       "  'Neptune']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant who is able to provide answers to questions\"\n",
    "user_prompt = \"Answer the following question: What are the names of planet in Earth's solar system.\"\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"{user_prompt}. Respond with format: {format_instruction}\",\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instruction\": JsonOutputParser().get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(json_prompt)\n",
    "\n",
    "chain = json_prompt | groq_llm | JsonOutputParser()\n",
    "chain.invoke({\"user_prompt\":user_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a017fe",
   "metadata": {},
   "source": [
    "## Use JsonOutputParser with ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4008665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['system_prompt', 'user_prompt'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['system_prompt'], input_types={}, partial_variables={}, template='{system_prompt}. Respond with JSON object'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_prompt'], input_types={}, partial_variables={}, template='{user_prompt}'), additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': ['Mercury',\n",
       "  'Venus',\n",
       "  'Earth',\n",
       "  'Mars',\n",
       "  'Jupiter',\n",
       "  'Saturn',\n",
       "  'Uranus',\n",
       "  'Neptune']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant who is able to provide answers to questions\"\n",
    "user_prompt = \"Answer the following question: What are the names of planet in Earth's solar system.\"\n",
    "\n",
    "json_prompt2 = ChatPromptTemplate([\n",
    "    (\"system\", \"{system_prompt}. Respond with JSON object\"),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "    \n",
    "print(json_prompt2)\n",
    "\n",
    "chain = json_prompt2 | groq_llm | JsonOutputParser()\n",
    "chain.invoke({\"system_prompt\":system_prompt, \"user_prompt\":user_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5323798",
   "metadata": {},
   "source": [
    "## Use SystemMessagePromptTemplate and HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd220d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant that helps generate article titles.\n",
    "\"\"\")\n",
    "                                                           \n",
    "article_text = \"\"\"AI is a useful tool for creative purposes. It can write text, create images and videos and act as a useful\n",
    "assistant to the creator. Rather than thinking of AI as a threat, we need to embrace its power to be more productive\n",
    "and experiment more and delegate the mundaneness to our digital assistant.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb5232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are looking at an article text:\n",
    "    ---\n",
    "    {article_text}\n",
    "    --- \n",
    "    Generate a suitable title for the same.\n",
    "    The tone of the title should be comic yet catchy.\"\"\",\n",
    "    input_variables=[\"article_text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959d727a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='You are looking at an article text:\\n    ---\\n    AI is a useful tool for creative purposes. It can write text, create images and videos and act as a useful\\nassistant to the creator. Rather than thinking of AI as a threat, we need to embrace its power to be more productive\\nand experiment more and delegate the mundaneness to our digital assistant.\\n    --- \\n    Generate a suitable title for the same.\\n    The tone of the title should be comic yet catchy.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using input_variables in the prompt template\n",
    "user_prompt.format(article_text=article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_messages([system_message, user_prompt])\n",
    "print(first_prompt.format(article_text=article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96730cc8",
   "metadata": {},
   "source": [
    "Now my prompt is ready, I have defined my model as well as input. Now its time to feed the prompt to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c579637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = ({\"article_text\": lambda x: x[\"article_text\"]} \n",
    "             | first_prompt\n",
    "             | llm\n",
    "             | {\"article_title\": lambda x: x.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e355d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_output = chain_one.invoke({\"article_text\": article_text})[\"article_title\"]\n",
    "title_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55f852",
   "metadata": {},
   "source": [
    "* So we have generated article title using LLM.\n",
    "\n",
    "* Next we'll patch this title with the article and generate an article summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e097cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_system_prompt = SystemMessagePromptTemplate.from_template(\"\"\"You are a helpful assistant who is able to help in building good articles.\n",
    "                                                                 \"\"\")\n",
    "\n",
    "\n",
    "second_user_prompt = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "You have access to an article: \n",
    "{article_text} alongwith its title: {article_title}. \n",
    "Generate a crisp summary for the article using this information. Make sure that the summary is less than 100 characters.\n",
    "The description should be in a SEO compatible format and suitable to show up on Google when this appears in search results\"\"\",\n",
    "input_variables = [\"article_text\", \"article_title\"])\n",
    "\n",
    "\n",
    "second_prompt = ChatPromptTemplate([second_system_prompt, second_user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed331df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_two = (\n",
    "    {\n",
    "        \"article_text\": lambda x: x[\"article_text\"],\n",
    "        \"article_title\": lambda x: x[\"title\"]\n",
    "    }\n",
    "    | second_prompt\n",
    "    | llm\n",
    "    | {\"article_summary\": lambda x: x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97dd0d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_summary': 'Discover how AI enhances creativity, empowering you to produce art and delegate mundane tasks.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_summary = chain_two.invoke({\"article_text\": article_text, \"title\": title_output })\n",
    "article_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a39f46",
   "metadata": {},
   "source": [
    "* We'll ask the LLM for unstructured outputs helping the user to write better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c8c24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_user_prompt = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "You are tasked with writing a new paragraph for the article.\n",
    "The article is as follows:\n",
    "{article_text}\n",
    "You can pick some part of the text and provide constructive feedback to the\n",
    "user so that they can improve their own writing.                                                  \n",
    "\"\"\",\n",
    "input_variables = [\"article_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2626d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_prompt = ChatPromptTemplate.from_messages([system_message, third_user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f2b5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paragraph(BaseModel):\n",
    "    original_paragraph: str = Field(description=\"The original paragraph\")\n",
    "    edited_paragraph: str = Field(description=\"The improved paragraph as edited by the model\")\n",
    "    feedback: str = Field(description=\"Constructive feedback on the original paragraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b168d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25228b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_three = (\n",
    "    {\"article_text\": lambda x: x[\"article_text\"]}\n",
    "    | third_prompt\n",
    "    | structured_llm\n",
    "    | {\n",
    "        \"original_paragraph\": lambda x: x.original_paragraph,\n",
    "        \"edited_paragraph\": lambda x: x.edited_paragraph,\n",
    "        \"feedback\": lambda x: x.feedback\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4dcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_output = chain_three.invoke({\"article_text\": article_text})\n",
    "third_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5eae57",
   "metadata": {},
   "source": [
    "# Adding Validations Using Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332917e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'planet_name': 'Mercury', 'distance': '77 million kilometers'},\n",
       " {'planet_name': 'Venus', 'distance': '41 million kilometers'},\n",
       " {'planet_name': 'Mars', 'distance': '225 million kilometers'},\n",
       " {'planet_name': 'Jupiter', 'distance': '778 million kilometers'},\n",
       " {'planet_name': 'Saturn', 'distance': '1.4 billion kilometers'},\n",
       " {'planet_name': 'Uranus', 'distance': '2.7 billion kilometers'},\n",
       " {'planet_name': 'Neptune', 'distance': '4.5 billion kilometers'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant who is able to provide answers to questions\"\n",
    "user_prompt = \"Answer the following question: What are the names of planet in Earth's solar system. Tell me distance of each planet from earth in kilometers\"\n",
    "\n",
    "class DataStructure(BaseModel):\n",
    "    planet_name: str = Field(description=\"name of the planet\")\n",
    "    distance: str = Field(description=\"distance of planet from earth\")\n",
    "\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"{user_prompt}. Respond with format: {format_instruction}\",\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instruction\": JsonOutputParser(pydantic_object=DataStructure).get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = json_prompt | groq_llm | JsonOutputParser()\n",
    "chain.invoke({\"user_prompt\":user_prompt})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
