{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06d540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (ChatPromptTemplate, \n",
    "                                    SystemMessagePromptTemplate, \n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    AIMessagePromptTemplate,\n",
    "                                    FewShotChatMessagePromptTemplate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df471a",
   "metadata": {},
   "source": [
    "# Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344a6da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['context', 'query']\n",
      "[['context'], ['query']]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"Answer the question based on provided context. If you dont know the answer say I dont know. \n",
    "Context: {context} \"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "print(prompt.input_variables)\n",
    "print([message.input_variables for message in prompt.messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78fed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Answer the question based on provided context. If you dont know the answer say I dont know. \\nContext: {context} '), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aeeaa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['context'], ['query']]\n"
     ]
    }
   ],
   "source": [
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt, input_variables=[\"context\"]),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])\n",
    "\n",
    "print([message.input_variables for message in prompt2.messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d97d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"This is a sample text\" \n",
    "query = \"The response should be a random sequence of two words from the context only.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoeke({\"context\": context, \"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ba239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    {\"context\": lambda x: x[\"context\"], \"query\": lambda x: x[\"query\"]}\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba959d",
   "metadata": {},
   "source": [
    "# Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7560001",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c31500d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"This is query #1\", \"output\": \"This is output #1\"},\n",
    "    {\"input\": \"This is query #2\", \"output\": \"This is output #2\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e76cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=prompt3,\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4310e8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotChatMessagePromptTemplate(examples=[{'input': 'This is query #1', 'output': 'This is output #1'}, {'input': 'This is query #2', 'output': 'This is output #2'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26da5f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: This is query #1\n",
      "AI: This is output #1\n",
      "Human: This is query #2\n",
      "AI: This is output #2\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b119dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    few_shot_prompt,\n",
    "    (\"user\", \"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0b2342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Answer the question based on provided context. If you dont know the answer say I dont know. \\nContext: {context} '), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'This is query #1', 'output': 'This is output #1'}, {'input': 'This is query #2', 'output': 'This is output #2'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16933a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721e7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
