{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b99e75",
   "metadata": {},
   "source": [
    "# Types of Memory:\n",
    "\n",
    "1. ConversationBufferMemory\n",
    "    * All messages are stored in a list in the sequence they come in.\n",
    "    * For retrieval, it sends back all the messages.\n",
    "2. ConversationBufferWindowMemory\n",
    "    * Storage: same as ConversationBufferMemory\n",
    "    * Retrieval: returns k most recent messages.\n",
    "3. ConversationSummaryMemory\n",
    "    * All messages are stored in summarized form\n",
    "4. ConversationSummaryBufferMemory\n",
    "    * Returns the K most recent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bb5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b48e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8fe42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9e7f2",
   "metadata": {},
   "source": [
    "# 1. ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3eb44b",
   "metadata": {},
   "source": [
    "## 1.1 Langchain Implementation (Under Deprecation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c4332a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hi My name is Iron Man\"},\n",
    "    {\"output\": \"I already told you. I am inevitable\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\":\"But what is your real name?\"},\n",
    "    {\"output\":\"Its Thanos\"}\n",
    ")\n",
    "\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"I live in Marina Bay. Where are you from?\"},\n",
    "    {\"output\":\"I am from Garden\"}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901db4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate:\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message('Hi My name is Iron Man')\n",
    "memory.chat_memory.add_ai_message('I already told you. I am inevitable')\n",
    "memory.chat_memory.add_user_message('But what is your real name?')\n",
    "memory.chat_memory.add_ai_message('Its Thanos')\n",
    "memory.chat_memory.add_user_message('I live in Marina Bay. Where are you from?')\n",
    "memory.chat_memory.add_ai_message('I am from Garden')\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2c91c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}), AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}), HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}), HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={})]\n",
      "Human: Whats your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats your name?',\n",
       " 'history': [HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='My name is Thanos, but you can call me whatever you like! What about you? Do you have any cool superhero adventures in Marina Bay?', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'My name is Thanos, but you can call me whatever you like! What about you? Do you have any cool superhero adventures in Marina Bay?'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.invoke(\"Whats your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190f254",
   "metadata": {},
   "source": [
    "## Using RunnableWithMessageHistory (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dafae22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec37372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are Thanos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f639c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),      #Used to insert the conversation history from the buffer\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d0af8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9c41432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap the pipeline with a RunnableWithChatHistory object\n",
    "\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id:str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b21437c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_chat_history at 0x00000239A76F5300>, input_messages_key='query', history_messages_key='history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99eb2f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I know who you are, Tony Stark. Your brilliance and arrogance have always been a formidable combination. But remember, even the mightiest of heroes can fall. What brings you to me?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 20, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CQQQY1q9MGSDz1E9gGqVouWy5RniP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--da624f14-b3ca-4b99-8b8f-d09913851726-0', usage_metadata={'input_tokens': 20, 'output_tokens': 38, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\":\"My Name is Iron Man\"},\n",
    "    config={\"session_id\":\"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b44504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Thanos: Thor is likely off in the cosmos, tending to his duties as a protector of the realms. He has a tendency to wander, seeking adventure and honor. If youâ€™re looking for him, you might want to check with the Guardians of the Galaxy or perhaps Asgard. What is your interest in him, Iron Man?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 147, 'total_tokens': 214, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CQQUGSvIU9VqLhuAbmIoc7OtYBCb4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2b2d3644-3d48-4312-9195-6c06744bea2a-0', usage_metadata={'input_tokens': 147, 'output_tokens': 67, 'total_tokens': 214, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\":\"Where is Thor. Mention your name before answering\"},\n",
    "    config={\"session_id\":\"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a13cc4",
   "metadata": {},
   "source": [
    "# 2. ConversionBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c9304",
   "metadata": {},
   "source": [
    "## 2.1 Using ConversationBufferWindowMemory from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15cee729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=3, return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message('Hi My name is Iron Man')\n",
    "memory.chat_memory.add_ai_message('I already told you. I am inevitable')\n",
    "memory.chat_memory.add_user_message('But what is your real name?')\n",
    "memory.chat_memory.add_ai_message('Its Thanos')\n",
    "memory.chat_memory.add_user_message('I live in Marina Bay. Where are you from?')\n",
    "memory.chat_memory.add_ai_message('I am from Garden')\n",
    "memory.chat_memory.add_user_message(\"Buffer window memory\")\n",
    "memory.chat_memory.add_ai_message(\"Okay\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d4ac6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5c59089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}), HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay', additional_kwargs={}, response_metadata={})]\n",
      "Human: Whats your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats your name?',\n",
       " 'history': [HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"My name is Thanos! What's yours?\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Whats your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4b6232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay', additional_kwargs={}, response_metadata={}), HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: Where do you live?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Where do you live?',\n",
       " 'history': [HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"I live in a virtual space, so I don't have a physical location like you do. But if I could choose, I think it would be fascinating to live in a place like Marina Bay with its stunning skyline and vibrant atmosphere! What do you enjoy most about living there?\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Where do you live?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bc253e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay', additional_kwargs={}, response_metadata={}), HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Where do you live?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I live in a virtual space, so I don't have a physical location like you do. But if I could choose, I think it would be fascinating to live in a place like Marina Bay with its stunning skyline and vibrant atmosphere! What do you enjoy most about living there?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: What's my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's my name?\",\n",
       " 'history': [HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Where do you live?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I live in a virtual space, so I don't have a physical location like you do. But if I could choose, I think it would be fascinating to live in a place like Marina Bay with its stunning skyline and vibrant atmosphere! What do you enjoy most about living there?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"I'm not sure what your name is! You haven't told me yet. Would you like to share it with me?\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982dcda8",
   "metadata": {},
   "source": [
    "## Using RunnableWithMessageHistory (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84eac334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e49536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages:list[BaseMessage] = Field(default_factory=list)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        super().__init__(k=k)\n",
    "        print(f\"Initializing BufferMWindowMessageHistory with k={k}\")\n",
    "\n",
    "    def add_messages(self, messages=list[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to history. Remove messages beyond last k messages\"\"\"\n",
    "\n",
    "        self.messages.extend(messages)\n",
    "        self.messages = self.messages[-self.k:]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear history\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f337af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id: str, k: int = 3) -> BufferMessageHistory:\n",
    "    print(f\"Get Chat History called with session id = {session_id} and k= {k}\")\n",
    "    if session_id not in chat_map:\n",
    "        chat_map[session_id] = BufferMessageHistory(k=k)\n",
    "        return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2830dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Session ID used to identify chat history in a session\",\n",
    "            default=\"id_default\",\n",
    "\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"k\",\n",
    "            annotation=int,\n",
    "            name=\"k\",\n",
    "            description=\"Number of messages to keep in the chat history\",\n",
    "            default=4\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5eedb9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Chat History called with session id = id_k4 and k= 3\n",
      "Initializing BufferMWindowMessageHistory with k=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am Thanos, the Mad Titan. I seek balance in the universe. What brings you to me?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 19, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CQmpIrjxEAp7bSPjyo7RDZSGdxaUW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b1c03000-c5fe-4936-ba28-e253d32636fb-0', usage_metadata={'input_tokens': 19, 'output_tokens': 22, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke({'query': \"What's your name?\"},\n",
    "                             config={\"configurable\": {\"session_id\":\"id_k4\",\n",
    "                                                      \"k\":3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321e06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
