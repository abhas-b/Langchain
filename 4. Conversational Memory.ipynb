{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b99e75",
   "metadata": {},
   "source": [
    "# Types of Memory:\n",
    "\n",
    "1. ConversationBufferMemory\n",
    "    * All messages are stored in a list in the sequence they come in.\n",
    "    * For retrieval, it sends back all the messages.\n",
    "2. ConversationBufferWindowMemory\n",
    "    * Storage: same as ConversationBufferMemory\n",
    "    * Retrieval: returns k most recent messages.\n",
    "3. ConversationSummaryMemory\n",
    "    * All messages are stored in summarized form\n",
    "4. ConversationSummaryBufferMemory\n",
    "    * Returns the K most recent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bb5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b48e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8fe42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9e7f2",
   "metadata": {},
   "source": [
    "# 1. ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3eb44b",
   "metadata": {},
   "source": [
    "## 1.1 Langchain Implementation (Under Deprecation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c4332a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hi My name is Iron Man\"},\n",
    "    {\"output\": \"I already told you. I am inevitable\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\":\"But what is your real name?\"},\n",
    "    {\"output\":\"Its Thanos\"}\n",
    ")\n",
    "\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"I live in Marina Bay. Where are you from?\"},\n",
    "    {\"output\":\"I am from Garden\"}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901db4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate:\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message('Hi My name is Iron Man')\n",
    "memory.chat_memory.add_ai_message('I already told you. I am inevitable')\n",
    "memory.chat_memory.add_user_message('But what is your real name?')\n",
    "memory.chat_memory.add_ai_message('Its Thanos')\n",
    "memory.chat_memory.add_user_message('I live in Marina Bay. Where are you from?')\n",
    "memory.chat_memory.add_ai_message('I am from Garden')\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2c91c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}), AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}), HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}), HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={})]\n",
      "Human: Whats your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats your name?',\n",
       " 'history': [HumanMessage(content='Hi My name is Iron Man', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I already told you. I am inevitable', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='My name is Thanos, but you can call me whatever you like! What about you? Do you have any cool superhero adventures in Marina Bay?', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'My name is Thanos, but you can call me whatever you like! What about you? Do you have any cool superhero adventures in Marina Bay?'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.invoke(\"Whats your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190f254",
   "metadata": {},
   "source": [
    "## Using RunnableWithMessageHistory (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dafae22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    ChatPromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec37372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are Thanos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f639c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),      #Used to insert the conversation history from the buffer\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d0af8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9c41432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap the pipeline with a RunnableWithChatHistory object\n",
    "\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id:str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b21437c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_chat_history at 0x00000239A76F5300>, input_messages_key='query', history_messages_key='history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99eb2f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I know who you are, Tony Stark. Your brilliance and arrogance have always been a formidable combination. But remember, even the mightiest of heroes can fall. What brings you to me?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 20, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CQQQY1q9MGSDz1E9gGqVouWy5RniP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--da624f14-b3ca-4b99-8b8f-d09913851726-0', usage_metadata={'input_tokens': 20, 'output_tokens': 38, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\":\"My Name is Iron Man\"},\n",
    "    config={\"session_id\":\"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b44504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Thanos: Thor is likely off in the cosmos, tending to his duties as a protector of the realms. He has a tendency to wander, seeking adventure and honor. If you’re looking for him, you might want to check with the Guardians of the Galaxy or perhaps Asgard. What is your interest in him, Iron Man?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 147, 'total_tokens': 214, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CQQUGSvIU9VqLhuAbmIoc7OtYBCb4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2b2d3644-3d48-4312-9195-6c06744bea2a-0', usage_metadata={'input_tokens': 147, 'output_tokens': 67, 'total_tokens': 214, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\":\"Where is Thor. Mention your name before answering\"},\n",
    "    config={\"session_id\":\"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a13cc4",
   "metadata": {},
   "source": [
    "# 2. ConversionBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c9304",
   "metadata": {},
   "source": [
    "## 2.1 Using ConversationBufferWindowMemory from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15cee729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=3, return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message('Hi My name is Iron Man')\n",
    "memory.chat_memory.add_ai_message('I already told you. I am inevitable')\n",
    "memory.chat_memory.add_user_message('But what is your real name?')\n",
    "memory.chat_memory.add_ai_message('Its Thanos')\n",
    "memory.chat_memory.add_user_message('I live in Marina Bay. Where are you from?')\n",
    "memory.chat_memory.add_ai_message('I am from Garden')\n",
    "memory.chat_memory.add_user_message(\"Buffer window memory\")\n",
    "memory.chat_memory.add_ai_message(\"Okay\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d4ac6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5c59089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}), HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay', additional_kwargs={}, response_metadata={})]\n",
      "Human: Whats your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats your name?',\n",
       " 'history': [HumanMessage(content='But what is your real name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Its Thanos', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"My name is Thanos! What's yours?\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Whats your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4b6232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay', additional_kwargs={}, response_metadata={}), HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: Where do you live?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Where do you live?',\n",
       " 'history': [HumanMessage(content='I live in Marina Bay. Where are you from?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I am from Garden', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"I live in a virtual space, so I don't have a physical location like you do. But if I could choose, I think it would be fascinating to live in a place like Marina Bay with its stunning skyline and vibrant atmosphere! What do you enjoy most about living there?\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Where do you live?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bc253e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay', additional_kwargs={}, response_metadata={}), HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Where do you live?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I live in a virtual space, so I don't have a physical location like you do. But if I could choose, I think it would be fascinating to live in a place like Marina Bay with its stunning skyline and vibrant atmosphere! What do you enjoy most about living there?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: What's my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's my name?\",\n",
       " 'history': [HumanMessage(content='Buffer window memory', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Okay', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Whats your name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"My name is Thanos! What's yours?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Where do you live?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I live in a virtual space, so I don't have a physical location like you do. But if I could choose, I think it would be fascinating to live in a place like Marina Bay with its stunning skyline and vibrant atmosphere! What do you enjoy most about living there?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"I'm not sure what your name is! You haven't told me yet. Would you like to share it with me?\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982dcda8",
   "metadata": {},
   "source": [
    "## Using RunnableWithMessageHistory (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84eac334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e49536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages:list[BaseMessage] = Field(default_factory=list)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        super().__init__(k=k)\n",
    "        print(f\"Initializing BufferMWindowMessageHistory with k={k}\")\n",
    "\n",
    "    def add_messages(self, messages=list[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to history. Remove messages beyond last k messages\"\"\"\n",
    "\n",
    "        self.messages.extend(messages)\n",
    "        self.messages = self.messages[-self.k:]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear history\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f337af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id: str, k: int = 3) -> BufferMessageHistory:\n",
    "    print(f\"Get Chat History called with session id = {session_id} and k= {k}\")\n",
    "    if session_id not in chat_map:\n",
    "        chat_map[session_id] = BufferMessageHistory(k=k)\n",
    "        return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2830dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Session ID used to identify chat history in a session\",\n",
    "            default=\"id_default\",\n",
    "\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"k\",\n",
    "            annotation=int,\n",
    "            name=\"k\",\n",
    "            description=\"Number of messages to keep in the chat history\",\n",
    "            default=4\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5eedb9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Chat History called with session id = id_k4 and k= 3\n",
      "Initializing BufferMWindowMessageHistory with k=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am Thanos, the Mad Titan. I seek balance in the universe. What brings you to me?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 19, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CQmpIrjxEAp7bSPjyo7RDZSGdxaUW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b1c03000-c5fe-4936-ba28-e253d32636fb-0', usage_metadata={'input_tokens': 19, 'output_tokens': 22, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke({'query': \"What's your name?\"},\n",
    "                             config={\"configurable\": {\"session_id\":\"id_k4\",\n",
    "                                                      \"k\":3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321e06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
